{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from src.models.unet import BaseUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).astype(np.uint8).flatten()\n",
    "    target = (target > threshold).astype(np.uint8).flatten()\n",
    "    \n",
    "    intersection = np.sum(pred * target)\n",
    "    return (2. * intersection) / (np.sum(pred) + np.sum(target) + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask_on_image(image, mask, alpha=0.5, color=(0, 255, 0)):\n",
    "\n",
    "    overlay = image.copy()\n",
    "    overlay[mask > 0] = color\n",
    "    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "\n",
    "def visualize_batch(images, predicteds, ground_truths, idx, gif_frames_preds, gif_frames_gt):\n",
    "    batch_size = len(images)\n",
    "    fig, ax = plt.subplots(batch_size, 3, figsize=(7.5, 30))\n",
    "\n",
    "    images = images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    predicteds = predicteds.cpu().numpy()\n",
    "    ground_truths = ground_truths.cpu().numpy()\n",
    "    dice_scores = []\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        img = images[i]\n",
    "        predicted = predicteds[i].squeeze()\n",
    "        ground_truth = ground_truths[i].squeeze()\n",
    "        \n",
    "        img_gray = (img.squeeze() * 255).astype(np.uint8)  \n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_clahe = clahe.apply(img_gray)\n",
    "        \n",
    "\n",
    "        img_3c = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # Overlay mask on the image\n",
    "        img_with_pred = overlay_mask_on_image(img_3c, predicted, color=(0, 255, 0))\n",
    "        img_with_gt   = overlay_mask_on_image(img_3c, ground_truth, color=(0, 0, 255))\n",
    "        \n",
    "        dice_score = dice_coefficient(predicted, ground_truth)\n",
    "        dice_scores.append(dice_score)\n",
    "        \n",
    "        \n",
    "        ax[i][0].imshow(img, cmap='gray')\n",
    "        ax[i][0].set_title('Original Image', fontsize=10)\n",
    "        \n",
    "        ax[i][1].imshow(img_clahe, cmap='bone')\n",
    "        ax[i][1].imshow(img_with_pred, alpha=0.5, cmap='gray')\n",
    "        ax[i][1].set_title('Image with predicted', fontsize=10)\n",
    "        \n",
    "        ax[i][2].imshow(img_clahe, cmap='bone')\n",
    "        ax[i][2].imshow(img_with_gt, alpha=0.5, cmap='gray')\n",
    "        ax[i][2].set_title('Image with ground truth', fontsize=10)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ax[i][j].set_yticks([])\n",
    "            ax[i][j].set_xticks([])\n",
    "\n",
    "        #combined_img = ax[i][1].get_images()[0].make_image(renderer=None, unsampled=True)[0]\n",
    "        gif_frames_preds.append(img_with_pred)\n",
    "        gif_frames_gt.append(img_with_gt)\n",
    "        #gif_frames.append(combined_img)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'batch_{idx}.jpg')\n",
    "    print(np.mean(dice_scores))\n",
    "    print(\"image saved\")\n",
    "\n",
    "\n",
    "# images       = images\n",
    "# predicted    = outputs\n",
    "# ground_truth = masks\n",
    "# visualize_batch(images, predicted, ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(gif_frames, gif_path, duration=0.5):\n",
    "    imageio.mimsave(gif_path, gif_frames, duration=duration)\n",
    "    print(f\"GIF saved at {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "load_path = '/home/syurtseven/gsoc-2024/reports/seg/2/model/model_20.pt'\n",
    "model  = BaseUNet(in_channels=1, out_channels=1)\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model  = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list  = sorted(glob.glob(os.path.join(\"/home/syurtseven/gsoc-2024/data/stomach_masks\", '*image*.png')))\n",
    "mask_list = sorted(glob.glob(os.path.join(\"/home/syurtseven/gsoc-2024/data/stomach_masks\", '*mask*.png')))\n",
    "bs = 16  \n",
    "img_batch_list = [] \n",
    "mask_batch_list = []  \n",
    "length_batch_list = []  \n",
    "\n",
    "\n",
    "for idx in range(0, len(img_list), bs):\n",
    "    img_seq_batch = []\n",
    "    mask_seq_batch = []  \n",
    "    for i in range(len(img_list[idx:idx + bs])):\n",
    "        i += idx  \n",
    "        if i + 1 >= len(img_list):\n",
    "            break  \n",
    "        key = '_'.join(img_list[i + 1].split('/')[-1].split('_')[:2])\n",
    "        cokey = '_'.join(img_list[i].split('/')[-1].split('_')[:2])\n",
    "        \n",
    "\n",
    "        if key != cokey:\n",
    "            # print(\"Mismatch keys found:\")\n",
    "            # print(f\"key: {key}\")\n",
    "            # print(f\"cokey: {cokey}\")\n",
    "            break\n",
    "        \n",
    "        img_seq_batch.append(img_list[i])\n",
    "        mask_seq_batch.append(mask_list[i])\n",
    "        \n",
    "    img_batch_list.append(img_seq_batch)\n",
    "    mask_batch_list.append(mask_seq_batch)\n",
    "\n",
    "# # print the batch lists to check the batches created\n",
    "# for idx, (img_batch, mask_batch) in enumerate(zip(img_batch_list, mask_batch_list)):\n",
    "#     print(f\"Image Batch {idx + 1}: {img_batch}\")\n",
    "#     print(f\"Mask Batch {idx + 1}: {mask_batch}\")\n",
    "#     length_batch_list.append(len(img_batch))\n",
    "\n",
    "# # print the lengths of each batch\n",
    "# for idx, length in enumerate(length_batch_list):\n",
    "#     print(f\"Length of Batch {idx + 1}: {length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "gif_frames_preds = []\n",
    "gif_frames_gt = []\n",
    "for idxs, (img_batch, mask_batch) in enumerate(zip(img_batch_list, mask_batch_list)):\n",
    "    # print(f\"Image Batch {idx + 1}: {img_batch}\")\n",
    "    # print(f\"Mask Batch {idx + 1}: {mask_batch}\")\n",
    "    batch_img  = []\n",
    "    batch_mask = []\n",
    "    for idx, (img, mask) in enumerate(zip(img_batch, mask_batch)):\n",
    "\n",
    "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask, cv2.IMREAD_UNCHANGED)\n",
    "        img = transform(img)\n",
    "        mask = transform(mask)\n",
    "        \n",
    "        batch_img.append(img)\n",
    "        batch_mask.append(mask)\n",
    "\n",
    "    if len(batch_img) == 16 and len(batch_mask) == 16:\n",
    "        batch_img = torch.stack(batch_img)\n",
    "        batch_mask = torch.stack(batch_mask)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images, masks = batch_img.to(device), batch_mask.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            if idxs < 5:\n",
    "                count +=1\n",
    "                images       = images\n",
    "                predicted    = outputs\n",
    "                ground_truth = masks\n",
    "                visualize_batch(images, predicted, ground_truth, count, gif_frames_preds, gif_frames_gt)\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(gif_frames_preds, 'predicted.gif', duration=0.5)\n",
    "create_gif(gif_frames_gt, 'ground_truth.gif', duration=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
